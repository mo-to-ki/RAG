{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **事前準備**\n",
    "今回の RAG 開発で用いる変数を事前に準備しておきます。  \n",
    "※ 以下のような内容の settings.py を事前に準備しておいてください\n",
    "```python\n",
    "OPENAI_API_KEY = \"*\"\n",
    "OPENAI_MODEL = \"gpt-4o\"\n",
    "OPENAI_EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import (\n",
    "    OPENAI_API_KEY,\n",
    "    OPENAI_MODEL,\n",
    "    OPENAI_EMBEDDING_MODEL,\n",
    ")\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **データの加工**\n",
    "今回 LLM に読み込ませるデータを ./docs フォルダに用意しておきました。  \n",
    "まずはこの pdf ファイルをテキスト化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now loading:================================"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "reader = PdfReader(\"./docs/Labor.pdf\")\n",
    "\n",
    "page_text = []\n",
    "print(\"now loading:\", end=\"\")\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text().replace(\"\\n\", \" \").replace(\" \", \"\")\n",
    "    page_text.append(text)\n",
    "    print(\"=\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **トークン数の確認**\n",
    "LLM は、文章が与えられると、それを一度 token と言われる数値のまとまりに変換します。  \n",
    "基本的に、料金や入力の可否はこの token の数によって決まるので、これが最大になっているページの token 数を見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_token: 1682\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(OPENAI_MODEL)\n",
    "max_token = 0\n",
    "for text in page_text[2:]:\n",
    "    token_integers = encoding.encode(text)\n",
    "    num_tokens = len(token_integers)\n",
    "    if num_tokens > max_token:\n",
    "        max_token = num_tokens\n",
    "print(\"max_token:\", max_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回使う GPT-4o という OpenAI のモデルでは 128,000 token 数まで入力できるので、今回他のは特別な必要なさそうです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ページごとに文章をベクトル化して jsonl に保存**\n",
    "今回作成しようとしていた RAG とは\n",
    ">   プロンプトがユーザーから与えられた際に、その回答を作成するのに必要そうなデータをプロンプトと一緒に LLM に与えることで、回答の精度向上を目指す。\n",
    "\n",
    "ものでした。  \n",
    "\n",
    "「回答を作成するのに必要そうなデータ」を見分けるために文章の類似度を用います。  \n",
    "プロンプトに似た内容が書いてあるページの情報だけを LLM に与えようということです。  \n",
    "そこで、文章の類似度を評価するために、一度文章をベクトル化します。  \n",
    "これを embedding といい、今回は OpenAI が提供しているモデルを使って行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ 多少お金がかかるので2度は実行しない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_CLIENT = OpenAI()\n",
    "\n",
    "output_file = \"./json/data.jsonl\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for text in page_text[3:]:\n",
    "        json_data = {\n",
    "            \"text\": text,\n",
    "            \"embedding\": OPENAI_CLIENT.embeddings.create(\n",
    "                input=text,\n",
    "                model=OPENAI_EMBEDDING_MODEL\n",
    "            ).data[0].embedding\n",
    "        }\n",
    "        json_line = json.dumps(json_data, ensure_ascii=False)\n",
    "        f.write(json_line + \"\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
